Building DAG of jobs...
The code used to generate one or several output files has changed:
    To inspect which output files have changes, run 'snakemake --list-code-changes'.
    To trigger a re-run, use 'snakemake -R $(snakemake --list-code-changes)'.
The input used to generate one or several output files has changed:
    To inspect which output files have changes, run 'snakemake --list-input-changes'.
    To trigger a re-run, use 'snakemake -R $(snakemake --list-input-changes)'.
The params used to generate one or several output files has changed:
    To inspect which output files have changes, run 'snakemake --list-params-changes'.
    To trigger a re-run, use 'snakemake -R $(snakemake --list-params-changes)'.
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job      count    min threads    max threads
-----  -------  -------------  -------------
test         1              1              1
total        1              1              1

Select jobs to execute...

[Thu Feb 24 16:30:11 2022]
rule test:
    output: output/test.txt
    jobid: 0
    resources: tmpdir=/var/folders/zk/7cx059j91lqbwvk7qk6kky6r0000gn/T

[Thu Feb 24 16:30:11 2022]
Finished job 0.
1 of 1 steps (100%) done
Complete log: /Users/alexstern/ukbb_ss_pipeline/.snakemake/log/2022-02-24T163010.849889.snakemake.log
